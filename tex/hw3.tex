\documentclass{article}
\input{structure.tex} % Include the file specifying the document structure and custom commands

\title{Probability and Stochastic Processes (1)}
\author{Yu Yangcheng, 2023010719\\ Tsinghua University}
\date{\textbf{Mar. 4, 2025}}

\begin{document}

\maketitle

\section*{Problem Set 3}

\begin{question}
\textbf{Communication through a noisy channel.} A source transmits a message (a string of symbols) through a noisy communication channel. Each symbol is 0 or 1 with probability $p$ and $1 - p$, respectively, and is received incorrectly with probability $\varepsilon_0$ and $\varepsilon_1$, respectively(see Fig. 1). Errors in different symbol transmissions are independent.

\begin{enumerate}[(a)]
    \item What is the probability that the $k$-th symbol is received correctly?
    \item What is the probability that the string of symbols 1011 is received correctly?
    \item In an effort to improve reliability, each symbol is transmitted three times and the received string is decoded by majority rule. In other words, a 0 (or 1) is transmitted as 000 (or 111, respectively), and it is decoded at the receiver as a 0 (or 1) if and only if the received three-symbol string contains at least two 0s (or 1s, respectively). What is the probability that a 0 is correctly decoded?
    \item For what values of $\varepsilon_0$ is there an improvement in the probability of correct decoding of a 0 when the scheme of part (c) is used?
    \item Suppose that the scheme of part (c) is used. What is the probability that a symbol was 0 given that the received string is 101?
\end{enumerate}
\end{question}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{fig118.png}  % 替换 image.png 为你的图片路径
    \caption{Error probabilities in a binary communication channel.}
    \label{fig:example}
\end{figure}

{\bf Solution.} 
Let A = "The original symbol is 0", $A^c$ = "The original symbol is 1". 
\begin{enumerate}[(a)]
    \item For k-th symbol in the string, the probability of being received successfully could be divided into two parts based on the original symbol. Under Bayes's rule, we have $$ \begin{align}
    P(\text{The k-th symbol is received correctly})&= P(\text{The k-th symbol is received correctly} | A) \\
    &+ P(\text{The k-th symbol is received correctly} | A^c)\\
    &= p (1-\varepsilon_0) + (1-p) (1-\varepsilon)
    \end{align} $$
    \item Each symbol's transmissions are independent, let $A_i = P(\text{the i-th symbol is received correctly})$, then 
    $$ \begin{align}
    P(A_1 \cap A_2 \cap A_3 \cap A_4) &= P(A_1)P(A_2)P(A_3)P(A_4) \\
    &= (1-\varepsilon_1)(1-\varepsilon_0)(1-\varepsilon_1)^2\\
    &= (1-\varepsilon)(1-\varepsilon)^3
    \end{align} $$
    \item 0 is transmitted as 000, and is decoded correctly iff. the received code has two or three codes. 
    $$ P(\text{0 is decoded correctly}) = (1-\varepsilon_0)^3+3\times \varepsilon_0(1-\varepsilon_0)^2 =(1+2\varepsilon_0)(1-\varepsilon_0)^2$$
    \item If there is an improvement in the probability of correct decoding of 0, then
    $$ (1+2\varepsilon_0)(1-\varepsilon_0) \geq 1$$
    That's to say, 
    $$ 0 < \varepsilon_0 < \frac{1}{2} $$
    \item Let C = "The received string is 101". Apply the theorem of conditional probability, we get
    $$ \begin{align}
        P(A|C) &= \frac{P(C|A)P(A)}{P(C)}\\
        &= \frac{p\varepsilon_0^2(1-\varepsilon_0)}{p\varepsilon_0^2(1-\varepsilon_0)+(1-p)\varepsilon_1(1-\varepsilon_1)^2}
    \end{align} $$
\end{enumerate}

\begin{question}
A and B play a series of games. Each game is independently won by A with probability $p$ and by B with probability $1 - p$. They stop when the total number of wins of one of the players is two greater than that of the other player. The player with the greater number of total wins is declared the winner of the series.

\begin{enumerate}[(a)]
    \item Find the probability that a total of 4 games are played.
    \item Find the probability that A is the winner of the series.
\end{enumerate}
\end{question}

{\bf Solution.}
\begin{enumerate}[(a)]
    \item If the game ends in exactly 4 turns, then there must be a player who wins 3 times while the other 1 times. For instance, if A is the winnner, then A would win the last game, and couldn't win the fist two games at a row(otherwise the game will end at two turns). So the possible cases are ABAA and BAAA.
    $$ P(\text{a total of 4 games are played})=2p^3(1-p) $$
    \item If A is the winnner of the series, then the game results could be: AA, AABA, BAAA... Note that the turns are always even numbers, because A wins two greater than B. Let the num of total games be 2k. The law is that in the 2k-turns series, A wins the last two game, and the 2i-1-th, 2i-th result must be AB or BA. 
    Then the total probability should be:
    $$ \begin{align}
    P(\text{A is the winner of the series}) &= p^2 + \left[2p(1-p)\right]p^2 + \left[2p(1-p)\right]^2p^2+\dots\\
    &= p^2\sum_{l=0}^{\infty}\left[2p(1-p)\right]^l\\
    & = \frac{p^2}{1-2p+2p^2} = \frac{p^2}{p^2+(1-p)^2}
    \end{align} $$
\end{enumerate}

\begin{question}
\begin{enumerate}[(a)]
    \item Show that the conditional independence of $A$ and $B$ given $C$ neither implies, nor is implied by, the independence of $A$ and $B$.
    \item For which event $C$ is it the case that, for arbitrary events $A$ and $B$, $A$ and $B$ are independent if and only if they are conditionally independent given $C$?
\end{enumerate}
\end{question}

{\bf Solution.}
"$\nRightarrow$": Suppose that A, B are not independent, for instance, P(AB) = 0.2, P(A) = 0.4, P(B)= 0.4. Then let $C=A\cap B$, we will find that 
$$ P(A\cap B|C) = 1 = \frac{P(A)}{P(C)} \times \frac{P(B)}{P(A\cap B)}=P(A|C)P(B|C)$$
That's to say, A and B are conditional independent given C. But A and B are not independent, implies that the first statement couldn't imply the second. \\
"$\nLeftarrow$": If A and B are independent, then 
$$ P(A\cap B)=P(A)P(B) $$
For example, P(A)=0.2, P(B)=0.2, P(AB)=0.04. Then 
$$ \begin{align}
    P(A\cap B | C)&=P(A|C)P(B|C)\\
    \iff \frac{P(ABC)}{P(C)}&=\frac{P(AC)}{P(C)}\cdot \frac{P(BC)}{P(C)}\\
\end{align} $$
Let C be $A\cup B$, then
$$ \begin{align}
    \frac{P(ABC)}{P(C)}&=\frac{P(AC)}{P(C)}\cdot \frac{P(BC)}{P(C)}\\
    \iff \frac{P(AB)}{P(C)}&=\frac{P(A)}{P(C)}\cdot \frac{P(B)}{P(C)}\\
    \iff P(C)&= 1
\end{align} $$
Obviously, for the example above, P(C)=0.2+0.2-0.04=0.36 $\neq $1.That leads to conflict, means that the first statement couldn't be implied by the second.
\begin{question}
Jane has three children, each of which is equally likely to be a boy or a girl independently of the others. Define the events:

\begin{itemize}
    \item $A$ = \{all the children are of the same sex\},
    \item $B$ = \{there is at most one boy\},
    \item $C$ = \{the family includes a boy and a girl\}.
\end{itemize}

\begin{enumerate}[(a)]
    \item Show that $A$ is independent of $B$, and that $B$ is independent of $C$.
    \item Is $A$ independent of $C$?
    \item Do these results hold if boys and girls are not equally likely?
    \item Do these results hold if Jane has four children?
\end{enumerate}
\end{question}

{\bf Solution.}
\begin{enumerate}[(a)]
    \item By calculation, we get
    $$ 
    \begin{align*}
        &P(AB)=\left(\frac{1}{2}\right)^3 = \frac{1}{8}=\frac{1}{4}\times (\frac{1}{8}+3\times \frac{1}{8})= P(A)\cdot P(B) \\
        &P(BC)=3\times \frac{1}{8}=(\frac{1}{8}+3\times\frac{1}{8})\times (6 \times \frac{1}{8}) = P(B)\cdot P(C) 
    \end{align*}
    $$
    \item Consider $A\cap C$, whose probability is zero for A, C are disjoint. But P(A),P(B) are not equal to zero, therefore 
    $$ P(AC)\neq P(A)(C)$$
    \item Let P(the children is a boy) be $p$, P(the children is a girl) be $1-p$. Then 
    $$
    \begin{align*}
    &P(AB)=(1-p)^3,P(A)=p^3+(1-p)^3,P(B)=(1-p)^3+3p(1-p)^2,\\
    &P(AB)\neq P(A)P(B)\\
    &P(BC)=3p(1-p)^2,P(B)=(1-p)^3+3p(1-p)^2,P(C)=3p(1-p)^2+3p^2(1-p),\\
    &P(BC)\neq P(B)P(C)\\
    &P(AC)=0\neq P(A)P(C)
    \end{align*}
    $$
    Therefore, (a) is not correct, but (b) still holds.
    \item Similarity, we have 
    $$ 
    \begin{align*}
        & P(AB)=(1-p)^4, P(A)=p^4+(1-p)^4, P(B)= (1-p)^4+4p(1-p)^3,\\
        &P(AB)\neq P(A)P(B)\\
        & P(BC)=4p(1-p)^3,P(B)=(1-p)^4+4p(1-p)^3,P(C)=8p^3(1-p)+6p^2(1-p)^2,\\
        & P(BC)\neq P(B)P(C)\\
        & P(AC)=0\neq P(A)P(C)
    \end{align*}
    $$
    Therefore, (a) is not correct, but (b) still holds.
\end{enumerate}

\begin{question}
Consider an infinite sequence of trials. The probability of success at the $i$-th trial is a positive number $p_i$, which satisfies $0 < p_i < 1$ and $\sum\limits_{i=1}^{\infty} p_i = \infty$. Assume that the trials are independent. Let $N$ be the event that there is no success, and let $I$ be the event that there is an infinite number of successes.

\begin{enumerate}[(a)]
    \item Let $n$ be a positive integer. Prove that $P(N) \leq \prod\limits_{i=1}^{n} (1 - p_i)$.
    \item Prove that $P(N) = 0$.\\
    \textit{Hint:} (1) Take logarithms on both sides of (a). (2) For $x < 1$, $\log (1 - x) \leq -x$.
    \item Let $L_n$ be the event that there is a finite number of successes and the last success occurs at the $n$-th trial. Prove that $P(L_n) = 0$.
    \item Prove that $P(I) = 1$.\\
    \textit{Hint:} Prove $P(I^c) = 0$ by expressing $I^c$ as a union of disjoint events.
\end{enumerate}
\end{question}

{\bf Solution.}
\begin{enumerate}[(a)]
    \item 
    $ P(N)=P(\text{there is no success in the first n trials})P(\text{there is no success after n trials})$, and P<1, so $P(N) \leq P(\text{there is no success in the first n trials})=\prod_{i=1}^{n}(1-p_i)$.
    \item Given (a)'s conclusion, we have 
    $$ \begin{align*}
        \log P(N) &\leq \log \prod_{i=1}^{n}(1-p_i)
        &\leq \sum_{i=1}^{n}\log (1-p_i)
        &\leq -\sum_{i=1}^{n}p_i 
    \end{align*} $$
    Since $ \sum_{i=1}^\infty p_i = \infty $, as $ n \to \infty $, $ \sum_{i=1}^n p_i \to \infty $. Thus:
    $$
    \ln P(N) \leq -\infty \implies P(N) = 0.
    $$
    \item The event $ L_n $ (last success at trial $ n $) requires:
        \begin{itemize}
        \item A success at trial $ n $: probability $ p_n $,
        \item No successes after trial $ n $: probability $ \prod_{i=n+1}^\infty (1 - p_i) $.
        \end{itemize}
        By part (b), $ \prod_{i=n+1}^\infty (1 - p_i) = 0 $. Thus:
        $$
        P(L_n) = p_n \cdot 0 = 0.
        $$
    \item The complement $ I^c $ (finitely many successes) is the union of disjoint events:
        $$
        I^c = \bigcup_{n=1}^\infty L_n.
        $$
        By countable additivity and part (c):
        $$
        P(I^c) = \sum_{n=1}^\infty P(L_n) = \sum_{n=1}^\infty 0 = 0.
        $$
        Therefore:
        $$
        P(I) = 1 - P(I^c) = 1 - 0 = 1.
        $$
\end{enumerate}


\end{document}
